{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: networkx in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (3.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from seaborn) (1.26.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from seaborn) (2.2.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openai in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (1.10.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (0.1.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.14 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain) (0.0.16)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain) (0.1.16)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain) (0.0.83)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/yeo_menghan/Documents/datathon/.venv/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install networkx\n",
    "%pip install seaborn\n",
    "%pip install openai\n",
    "%pip install langchain\n",
    "%pip install scikit-learn\n",
    "% pip install transformers sentence-transformers\n",
    "# add commented pip installation lines for packages used as shown above for ease of testing\n",
    "# the line should be of the format %pip install PACKAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .csv file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can have as many cells as you want for code\n",
    "import pandas as pd\n",
    "filepath = \"./data/catA_train.csv\"\n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>Company</th>\n",
       "      <th>SIC Code</th>\n",
       "      <th>Industry</th>\n",
       "      <th>8-Digit SIC Code</th>\n",
       "      <th>8-Digit SIC Description</th>\n",
       "      <th>Year Found</th>\n",
       "      <th>Entity Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Employees (Global Ultimate Total)</th>\n",
       "      <th>Sales (Domestic Ultimate Total USD)</th>\n",
       "      <th>Sales (Global Ultimate Total USD)</th>\n",
       "      <th>Import/Export Status</th>\n",
       "      <th>Fiscal Year End</th>\n",
       "      <th>Global Ultimate Company</th>\n",
       "      <th>Global Ultimate Country</th>\n",
       "      <th>Domestic Ultimate Company</th>\n",
       "      <th>Is Domestic Ultimate</th>\n",
       "      <th>Is Global Ultimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.285495</td>\n",
       "      <td>103.843852</td>\n",
       "      <td>LAKB2BID4559214</td>\n",
       "      <td>FRANK CONSULTING SERVICES PRIVATE LIMITED</td>\n",
       "      <td>7361</td>\n",
       "      <td>Employment Agencies</td>\n",
       "      <td>73610000</td>\n",
       "      <td>Employment agencies</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Subsidiary</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.209224e+06</td>\n",
       "      <td>4.637871e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FINDERS HOLDCO LIMITED</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>FRANK RECRUITMENT GROUP PRIVATE LTD.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.291294</td>\n",
       "      <td>103.827476</td>\n",
       "      <td>LAKB2BID7610849</td>\n",
       "      <td>NEW DESERT ORCHID SHIPPING PTE. LTD.</td>\n",
       "      <td>4449</td>\n",
       "      <td>Water Transportation of Freight, Not Elsewhere...</td>\n",
       "      <td>44490000</td>\n",
       "      <td>Water transportation of freight</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Subsidiary</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.093536e+09</td>\n",
       "      <td>7.093536e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PETREDEC PTE. LIMITED</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.300144</td>\n",
       "      <td>103.857517</td>\n",
       "      <td>LAKB2BID5461679</td>\n",
       "      <td>2MBAO BIOCELLBANK PTE. LTD.</td>\n",
       "      <td>6719</td>\n",
       "      <td>Offices of Holding Companies, Not Elsewhere Cl...</td>\n",
       "      <td>67190000</td>\n",
       "      <td>Holding companies, nec</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>Subsidiary</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.026308e+06</td>\n",
       "      <td>1.026308e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MADISON LIGHTERS AND WATCHES CO LTD</td>\n",
       "      <td>Hong Kong SAR</td>\n",
       "      <td>2MBAO BIOCELLBANK PTE. LTD.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.300785</td>\n",
       "      <td>103.791263</td>\n",
       "      <td>LAKB2BID5088529</td>\n",
       "      <td>NEWBLOOM PTE. LTD.</td>\n",
       "      <td>6719</td>\n",
       "      <td>Offices of Holding Companies, Not Elsewhere Cl...</td>\n",
       "      <td>67190000</td>\n",
       "      <td>Holding companies, nec</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Subsidiary</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.339898e+10</td>\n",
       "      <td>7.339898e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WILMAR INTERNATIONAL LIMITED</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>WILMAR INTERNATIONAL LIMITED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.298759</td>\n",
       "      <td>103.859430</td>\n",
       "      <td>LAKB2BID1268831</td>\n",
       "      <td>ASIA GREEN CAPITAL PTE. LTD.</td>\n",
       "      <td>6719</td>\n",
       "      <td>Offices of Holding Companies, Not Elsewhere Cl...</td>\n",
       "      <td>67190000</td>\n",
       "      <td>Holding companies, nec</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Parent</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.322130e+05</td>\n",
       "      <td>4.322130e+05</td>\n",
       "      <td>Exports</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASIA GREEN CAPITAL PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>ASIA GREEN CAPITAL PTE. LTD.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LATITUDE   LONGITUDE        AccountID  \\\n",
       "0  1.285495  103.843852  LAKB2BID4559214   \n",
       "1  1.291294  103.827476  LAKB2BID7610849   \n",
       "2  1.300144  103.857517  LAKB2BID5461679   \n",
       "3  1.300785  103.791263  LAKB2BID5088529   \n",
       "4  1.298759  103.859430  LAKB2BID1268831   \n",
       "\n",
       "                                     Company  SIC Code  \\\n",
       "0  FRANK CONSULTING SERVICES PRIVATE LIMITED      7361   \n",
       "1       NEW DESERT ORCHID SHIPPING PTE. LTD.      4449   \n",
       "2                2MBAO BIOCELLBANK PTE. LTD.      6719   \n",
       "3                         NEWBLOOM PTE. LTD.      6719   \n",
       "4               ASIA GREEN CAPITAL PTE. LTD.      6719   \n",
       "\n",
       "                                            Industry  8-Digit SIC Code  \\\n",
       "0                                Employment Agencies          73610000   \n",
       "1  Water Transportation of Freight, Not Elsewhere...          44490000   \n",
       "2  Offices of Holding Companies, Not Elsewhere Cl...          67190000   \n",
       "3  Offices of Holding Companies, Not Elsewhere Cl...          67190000   \n",
       "4  Offices of Holding Companies, Not Elsewhere Cl...          67190000   \n",
       "\n",
       "           8-Digit SIC Description  Year Found Entity Type  ...  \\\n",
       "0              Employment agencies      2020.0  Subsidiary  ...   \n",
       "1  Water transportation of freight      2015.0  Subsidiary  ...   \n",
       "2           Holding companies, nec      1993.0  Subsidiary  ...   \n",
       "3           Holding companies, nec      2006.0  Subsidiary  ...   \n",
       "4           Holding companies, nec      2006.0      Parent  ...   \n",
       "\n",
       "  Employees (Global Ultimate Total) Sales (Domestic Ultimate Total USD)  \\\n",
       "0                               NaN                        2.209224e+06   \n",
       "1                             100.0                        7.093536e+09   \n",
       "2                               4.0                        1.026308e+06   \n",
       "3                             100.0                        7.339898e+10   \n",
       "4                               4.0                        4.322130e+05   \n",
       "\n",
       "  Sales (Global Ultimate Total USD) Import/Export Status  Fiscal Year End  \\\n",
       "0                      4.637871e+06                  NaN              NaN   \n",
       "1                      7.093536e+09                  NaN              NaN   \n",
       "2                      1.026308e+06                  NaN              NaN   \n",
       "3                      7.339898e+10                  NaN              NaN   \n",
       "4                      4.322130e+05              Exports              NaN   \n",
       "\n",
       "               Global Ultimate Company  Global Ultimate Country  \\\n",
       "0               FINDERS HOLDCO LIMITED           United Kingdom   \n",
       "1                PETREDEC PTE. LIMITED                Singapore   \n",
       "2  MADISON LIGHTERS AND WATCHES CO LTD            Hong Kong SAR   \n",
       "3         WILMAR INTERNATIONAL LIMITED                Singapore   \n",
       "4         ASIA GREEN CAPITAL PTE. LTD.                Singapore   \n",
       "\n",
       "              Domestic Ultimate Company  Is Domestic Ultimate  \\\n",
       "0  FRANK RECRUITMENT GROUP PRIVATE LTD.                     0   \n",
       "1                                   NaN                     0   \n",
       "2           2MBAO BIOCELLBANK PTE. LTD.                     1   \n",
       "3          WILMAR INTERNATIONAL LIMITED                     0   \n",
       "4          ASIA GREEN CAPITAL PTE. LTD.                     1   \n",
       "\n",
       "   Is Global Ultimate  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29182 entries, 0 to 29181\n",
      "Data columns (total 28 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   LATITUDE                             29062 non-null  float64\n",
      " 1   LONGITUDE                            29062 non-null  float64\n",
      " 2   AccountID                            29182 non-null  object \n",
      " 3   Company                              29182 non-null  object \n",
      " 4   SIC Code                             29182 non-null  int64  \n",
      " 5   Industry                             29182 non-null  object \n",
      " 6   8-Digit SIC Code                     29182 non-null  int64  \n",
      " 7   8-Digit SIC Description              29182 non-null  object \n",
      " 8   Year Found                           28748 non-null  float64\n",
      " 9   Entity Type                          29182 non-null  object \n",
      " 10  Parent Company                       28668 non-null  object \n",
      " 11  Parent Country                       28662 non-null  object \n",
      " 12  Ownership Type                       29182 non-null  object \n",
      " 13  Company Description                  29182 non-null  object \n",
      " 14  Square Footage                       0 non-null      float64\n",
      " 15  Company Status (Active/Inactive)     29182 non-null  object \n",
      " 16  Employees (Single Site)              16779 non-null  float64\n",
      " 17  Employees (Domestic Ultimate Total)  29103 non-null  float64\n",
      " 18  Employees (Global Ultimate Total)    26408 non-null  float64\n",
      " 19  Sales (Domestic Ultimate Total USD)  29182 non-null  float64\n",
      " 20  Sales (Global Ultimate Total USD)    29182 non-null  float64\n",
      " 21  Import/Export Status                 6613 non-null   object \n",
      " 22  Fiscal Year End                      6737 non-null   object \n",
      " 23  Global Ultimate Company              28668 non-null  object \n",
      " 24  Global Ultimate Country              28659 non-null  object \n",
      " 25  Domestic Ultimate Company            28147 non-null  object \n",
      " 26  Is Domestic Ultimate                 29182 non-null  int64  \n",
      " 27  Is Global Ultimate                   29182 non-null  int64  \n",
      "dtypes: float64(9), int64(4), object(15)\n",
      "memory usage: 6.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###...code...###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from IPython.display import display\n",
    "\n",
    "# Load csv\n",
    "data = pd.read_csv(filepath, encoding=\"unicode_escape\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
      "/var/folders/_l/9yt9fjns3yl8khq3hlylkj7w0000gn/T/ipykernel_24293/3559513227.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_data[col].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Cleaning Process\n",
    "\n",
    "# Identifying missing values\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Reviewing data types for each column\n",
    "data_types = data.dtypes\n",
    "\n",
    "# Displaying the missing values and data types for review\n",
    "missing_values, data_types\n",
    "\n",
    "# General approach to handling missing values\n",
    "# For columns with a small percentage of missing values, we can consider imputation\n",
    "# For columns with a high percentage of missing values, we might drop the column\n",
    "\n",
    "# Dropping columns with high missing values (>50%)\n",
    "columns_to_drop = missing_values[missing_values > data.shape[0] / 2].index\n",
    "cleaned_data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Imputing missing values for other columns\n",
    "# For numerical columns, we can use the mean or median\n",
    "# For categorical columns, we can use the mode or a placeholder value like 'Unknown'\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = cleaned_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = cleaned_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute numerical columns with the median\n",
    "for col in numerical_cols:\n",
    "    cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
    "\n",
    "# Impute categorical columns with 'Unknown'\n",
    "for col in categorical_cols:\n",
    "    cleaned_data[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Check if there are any missing values left\n",
    "remaining_missing_values = cleaned_data.isnull().sum().sum()\n",
    "\n",
    "remaining_missing_values, cleaned_data.head()\n",
    "\n",
    "# Define the path for the new cleaned CSV file\n",
    "cleaned_file_path = './data/cleaned_catA_train.csv'\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "cleaned_data.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Replace data with cleaned data\n",
    "data = cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data with 'Revenue (Total)' column has been saved to ./data/cleaned_catA_train_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = './data/cleaned_catA_train.csv'  # Replace with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Sort the DataFrame by 'SIC Code'\n",
    "df = df.sort_values(by='SIC Code', ascending=True)\n",
    "\n",
    "# Initialize a variable to store the last non-\"Not Elsewhere Classified\" SIC Code\n",
    "last_non_nec_sic_code = None\n",
    "\n",
    "# Iterate over the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    industry_name = row['Industry']\n",
    "\n",
    "    # Check if the industry name does not end with \"Not Elsewhere Classified\"\n",
    "    if \"Not Elsewhere Classified\" not in industry_name:\n",
    "        last_non_nec_sic_code = row['SIC Code']\n",
    "    else:\n",
    "        # Update the SIC Code for \"Not Elsewhere Classified\" industries\n",
    "        df.at[index, 'SIC Code'] = last_non_nec_sic_code\n",
    "        # Remove the \", Not Elsewhere Classified\" text from the 'Industry' column\n",
    "        df.at[index, 'Industry'] = industry_name.replace(\", Not Elsewhere Classified\", \"\").strip()\n",
    "\n",
    "# Add the two columns to create \"Employees (Total)\"\n",
    "df['Employees (Total)'] = df['Employees (Domestic Ultimate Total)'] + df['Employees (Global Ultimate Total)']\n",
    "\n",
    "# Add the two columns to create \"Revenue (Total)\"\n",
    "df['Sales (Total)'] = df['Sales (Domestic Ultimate Total USD)'] + df['Sales (Global Ultimate Total USD)']\n",
    "\n",
    "# Reorder the columns to put \"Employees (Total)\" and \"Revenue (Total)\" to the right of their respective components\n",
    "columns = df.columns.tolist()\n",
    "# Find the index of 'Employees (Global Ultimate Total)'\n",
    "global_ultimate_index = columns.index('Employees (Global Ultimate Total)')\n",
    "# Insert the 'Employees (Total)' column right after 'Employees (Global Ultimate Total)'\n",
    "columns.insert(global_ultimate_index + 1, columns.pop(columns.index('Employees (Total)')))\n",
    "# Find the index of 'Revenue (Global Ultimate Total)'\n",
    "revenue_global_ultimate_index = columns.index('Sales (Global Ultimate Total USD)')\n",
    "# Insert the 'Revenue (Total)' column right after 'Revenue (Global Ultimate Total)'\n",
    "columns.insert(revenue_global_ultimate_index + 1, columns.pop(columns.index('Sales (Total)')))\n",
    "# Reindex the dataframe with the new column order\n",
    "df = df.reindex(columns=columns)\n",
    "\n",
    "# Calculate and add a new column for \"Revenue per Employee\"\n",
    "df['Sales per Employee'] = df['Sales (Total)'] / df['Employees (Total)']\n",
    "\n",
    "# Define the path for the new cleaned CSV file\n",
    "cleaned_file_path = './data/cleaned_catA_train_updated.csv'\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(\"Cleaned data with 'Revenue (Total)' column has been saved to\", cleaned_file_path)\n",
    "\n",
    "# Replace data with cleaned data for further processing if needed\n",
    "data = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: ./data/sic_codes_1_to_999.csv\n",
      "Saved file: ./data/sic_codes_1001_to_1499.csv\n",
      "Saved file: ./data/sic_codes_1501_to_1799.csv\n",
      "Saved file: ./data/sic_codes_2001_to_3999.csv\n",
      "Saved file: ./data/sic_codes_4001_to_4999.csv\n",
      "Saved file: ./data/sic_codes_5001_to_5199.csv\n",
      "Saved file: ./data/sic_codes_5201_to_5999.csv\n",
      "Saved file: ./data/sic_codes_6001_to_6799.csv\n",
      "Saved file: ./data/sic_codes_7001_to_8999.csv\n",
      "Saved file: ./data/sic_codes_9001_to_9999.csv\n"
     ]
    }
   ],
   "source": [
    "## Generate 10 csv files per SIC code\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./data/cleaned_catA_train_updated.csv')\n",
    "\n",
    "# Define the SIC code ranges based on the image provided\n",
    "sic_code_ranges = [\n",
    "    (0, 999),\n",
    "    (1000, 1499),\n",
    "    (1500, 1799),\n",
    "    (2000, 3999),\n",
    "    (4000, 4999),\n",
    "    (5000, 5199),\n",
    "    (5200, 5999),\n",
    "    (6000, 6799),\n",
    "    (7000, 8999),\n",
    "    (9000, 9999)\n",
    "]\n",
    "\n",
    "# Split the dataframe and save separate CSV files for each SIC code range\n",
    "for lower_bound, upper_bound in sic_code_ranges:\n",
    "    # Filter the dataframe for the current SIC code range\n",
    "    filtered_df = df[(df['SIC Code'] > lower_bound) & (df['SIC Code'] <= upper_bound)]\n",
    "\n",
    "    # Define the filename based on the SIC code range\n",
    "    filename = f'./data/sic_codes_{lower_bound+1}_to_{upper_bound}.csv'\n",
    "\n",
    "    # Save to a new CSV file\n",
    "    filtered_df.to_csv(filename, index=False)\n",
    "    print(f\"Saved file: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 74178638.27503084\n",
      "Coefficient: -14711.554293851244\n",
      "Selected feature: Year Found\n",
      "R2 score: -0.09858567342205471\n",
      "Intercept: -7428200587.245547\n",
      "Coefficient: 3725100.107752283\n",
      "Selected feature: Is Domestic Ultimate\n",
      "R2 score: -80.14249903089758\n",
      "Intercept: 601071158.807969\n",
      "Coefficient: -295042.5763672729\n",
      "Selected feature: Parent Country_France\n",
      "R2 score: -0.17552082834504534\n",
      "Intercept: -281518096.7542463\n",
      "Coefficient: 123204.93601212265\n",
      "Selected feature: Parent Country_Australia\n",
      "R2 score: -0.002138129622664575\n",
      "Intercept: 489921937.4074286\n",
      "Coefficient: -84806.05345138125\n",
      "Selected feature: Is Domestic Ultimate\n",
      "R2 score: -0.02758719855207792\n",
      "Intercept: -103011749.33388332\n",
      "Coefficient: 62256.9172752775\n",
      "Selected feature: Parent Country_Bahamas\n",
      "R2 score: -8.688341027318636e-05\n",
      "Intercept: -28976618.3364275\n",
      "Coefficient: 12881.225533833227\n",
      "Selected feature: Parent Country_Cyprus\n",
      "R2 score: -0.020161658957718043\n",
      "Intercept: -559829065.9692295\n",
      "Coefficient: 270004.0719832304\n",
      "Selected feature: Parent Country_Antigua and Barbuda\n",
      "R2 score: -0.00018115135866003662\n",
      "Intercept: 298948.05760988966\n",
      "Coefficient: 42746.80194666002\n",
      "Selected feature: Parent Country_Bahamas\n",
      "R2 score: -0.0003768622599047422\n",
      "Intercept: -472148.94489321986\n",
      "Coefficient: 20.797888307324758\n",
      "Selected feature: Year Found\n",
      "R2 score: -1.095329951689933\n",
      "Saved file: ./data/test_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "## Loop through all 10 CSV files and store the test data into a test csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "\n",
    "file_names = [\"./data/sic_codes_1_to_999.csv\", \"./data/sic_codes_1001_to_1499.csv\",\n",
    "              \"./data/sic_codes_1501_to_1799.csv\", \"./data/sic_codes_2001_to_3999.csv\",\n",
    "              \"./data/sic_codes_4001_to_4999.csv\", \"./data/sic_codes_5001_to_5199.csv\",\n",
    "              \"./data/sic_codes_5201_to_5999.csv\", \"./data/sic_codes_6001_to_6799.csv\",\n",
    "              \"./data/sic_codes_7001_to_8999.csv\", \"./data/sic_codes_9001_to_9999.csv\"\n",
    "              ]  # Replace with your actual file names\n",
    "\n",
    "# DataFrame to store all test sets\n",
    "test_data_frames = []\n",
    "\n",
    "# Process each file\n",
    "for file in file_names:\n",
    "    # Load dataset\n",
    "    sic099 = pd.read_csv(file)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    sic099.drop(columns=['LATITUDE', 'LONGITUDE', 'AccountID', 'Industry', 'Company', 'SIC Code',\n",
    "                        '8-Digit SIC Code', '8-Digit SIC Description', 'Entity Type', 'Ownership Type',\n",
    "                        'Company Description', 'Company Status (Active/Inactive)', 'Employees (Single Site)',\n",
    "                        'Employees (Domestic Ultimate Total)', 'Employees (Global Ultimate Total)',\n",
    "                        'Sales (Domestic Ultimate Total USD)', 'Sales (Global Ultimate Total USD)',\n",
    "                        'Global Ultimate Company', 'Global Ultimate Country', 'Domestic Ultimate Company',\n",
    "                        'Parent Company'], inplace=True)\n",
    "\n",
    "    # Identify and one-hot encode categorical columns\n",
    "    categorical_cols = sic099.select_dtypes(include=['object']).columns\n",
    "    sic099 = pd.get_dummies(sic099, columns=categorical_cols)\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(3333)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X = sic099.drop(columns=['Sales per Employee'])\n",
    "    y = sic099['Sales per Employee']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3333)\n",
    "\n",
    "    # Train the linear regression model\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    # Print the model intercept and coefficient\n",
    "    print('Intercept:', model.intercept_)\n",
    "    print('Coefficient:', model.coef_[0])\n",
    "\n",
    "    # Apply RFE to find the most significant feature\n",
    "    rfe = RFE(estimator=LinearRegression(), n_features_to_select=13)\n",
    "    rfe.fit(X_train, y_train)\n",
    "\n",
    "    # Print the selected feature and R2 score\n",
    "    selected_feature = X_train.columns[rfe.support_][0]\n",
    "    print('Selected feature:', selected_feature)\n",
    "\n",
    "    r2 = r2_score(y_test, rfe.predict(X_test))\n",
    "    print('R2 score:', r2)\n",
    "\n",
    "    # Append the test set to the all_test_data DataFrame\n",
    "    test_data_frames.append(X_test)\n",
    "\n",
    "# Concatenate all test set DataFrames\n",
    "all_test_data = pd.concat(test_data_frames, ignore_index=True)\n",
    "\n",
    "# Save the combined test dataset to a CSV file\n",
    "filename = f'./data/test_dataset.csv'\n",
    "all_test_data.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Saved file: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
    "    '''DO NOT REMOVE THIS FUNCTION.\n",
    "\n",
    "The function accepts a dataframe as input and return an iterable (list)\n",
    "of binary classes as output.\n",
    "\n",
    "The function should be coded to test on hidden data\n",
    "and should include any preprocessing functions needed for your model to perform.\n",
    "\n",
    "All relevant code MUST be included in this function.'''\n",
    "\n",
    "    result = []\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should output a list of predictions.\n",
    "test_df = pd.read_csv(filepath)\n",
    "test_df = test_df.drop(columns=['Sales (Domestic Ultimate Total USD)'])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
